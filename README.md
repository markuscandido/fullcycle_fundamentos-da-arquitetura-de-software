# Fundamentos da arquitetura de software

Síntese do curso **Fundamentos da arquitetura de software**, parte integrante do [FullCycle 3.0](https://curso.fullcycle.com.br/curso-fullcycle/) by [Full Cycle](https://fullcycle.com.br/)

## Fundamentos

Compreender os diferentes tipos de arquitetura em Tecnologia da Informação é fundamental para expandir o conhecimento sobre como construir softwares de maneira eficaz. Existem vários tipos de arquiteturas, mas quatro são especialmente relevantes: **Arquitetura de Software**, **Arquitetura de Solução**, **Arquitetura Tecnológica** e **Arquitetura Corporativa**.

### Arquitetura tecnológica

Refere-se a especialistas em tecnologias específicas. Esses profissionais possuem um conhecimento profundo de determinadas ferramentas ou plataformas. São essenciais em projetos que requerem expertise detalhada, permitindo que as organizações maximizem o valor dessas tecnologias.

**Highlights**:

- Especialidade em tecnologias especificas de mercado
- Geração de valor baseado em especialidades
- Certificações

### Arquitetura Corporativa

Refere-se a criação de políticas e regras estratégicas que impactam toda a organização. Esse tipo de arquitetura é responsável por padronizar tecnologias, avaliar custos, e planejar grandes implantações. Em grandes empresas, como bancos ou software houses, a governança tecnológica é crucial para garantir alinhamento entre as áreas e evitar danos que a falta de padronização pode causa.

**Highlights**:

- Impacta estrategicamente a organização como um todo
- Avaliação de custos
- Avaliação de possíveis novas tecnologias
- Padronização de tecnologias
- Planejamento de grandes implantações
- Sistemas "core"
- Migrações

### Arquitetura de solução

Aqui o papel crucial é conectar as áreas de negócios e software. O arquiteto de soluções é um profissional técnico com uma visão clara dos requisitos de negócios, capaz de transformar essas necessidades em soluções de software. A habilidade de desenhar e documentar arquiteturas é fundamental, utilizando ferramentas como diagramas C4, UML, BPMN, entre outros, para expressar como o software será estruturado e funcionará.

Em resumo, o arquiteto de soluções é um profissional que combina conhecimentos técnicos com uma compreensão profunda dos negócios, capaz de traduzir necessidades empresariais em soluções de software viáveis e economicamente sustentáveis.

**Highlights**:

- Fica entre a área de negócios e software
- Transformar requisitos de negócio em soluções de software
- Desenhos arquiteturais da solução de um software para reproduzir como ele irá funcionar
- Análise de impactos comerciais em relação a uma escolha tecnológica

### O que é arquitetura de software

É uma disciplina essencial da engenharia de software, que impacta diretamente no processo de desenvolvimento e a estrutura organizacional das empresas. A arquitetura de software não apenas define como o software será construído, mas também influencia como os times de desenvolvimento serão organizados, conforme explicado pela **Lei de conway**.

A arquitetura de software vai além do simples desenho de sistemas, ela envolve a criação de componentes de software que atendam aos objetivos de negócio, considerando as restrições existentes, como financeiras, tecnológicas e de equipe.

Um dos aspectos mais importantes é pensar no longo prazo. Não basta projetar somente os componentes atuais do sistema, é necessário considerar como esses componentes evoluirão ao longo do tempo para garantir a sustentabilidade do software. A arquitetura de software, em resumo, é responsável por conectar os objetivos de negócio a um design que possibilita a evolução contínua do software, assegurando que ele seja capaz de atender às necessidades do negócio a curto, médio e longo prazo.

**Highlights**:

- É uma disciplina da engenharia de software
- Diretamente ligada ao processo de desenvolvimento de software
- Afeta diretamente na estrutura organizacional da empresa (Lei de Conway)

### O papel do arquiteto de software

O arquiteto de software desempenha um papel fundamental na transformação de requisitos de negócios em padrões arquiteturais, moldando a estrutura de toda a solução. Além de definir componentes e padrões, o arquiteto deve estar intimamente ligado aos desenvolvedores, muitas vezes atuando como ponte entre eles e os experts de domínio. Essa proximidade é essencial para garantir que o software atenda às reais necessidades dos usuários.

Em projetos de grande porte, a comunicação clara entre desenvolvedores e especialistas é vital, e o arquiteto facilita esse diálogo. Mais do que um papel técnico, o arquiteto precisa ter uma compreensão profunda dos modelos arquiteturais e ser capaz de adaptar sua abordagem com base no contexto do projeto. A diversidade de experiências e conhecimento em diferentes modelos arquiteturais amplia o leque de soluções possíveis, permitindo decisões mais adequadas para cada desafio.

O arquiteto também desempenha um papel crítico em momentos de crise, trazendo sua experiência para resolver problemas inesperados e reforçando boas práticas de desenvolvimento, como testes e padrões de design. Embora nem todas as organizações possuam um arquiteto formal, muitas vezes, desenvolvedores sêniores ou tech leads assumem essas responsabilidades, aplicando seus conhecimentos para orientar o desenvolvimento e garantir a sustentabilidade do software.

- [Manual do Arquiteto de Software](https://arquiteturadesoftware.online/)

**Highlights**:

- Transformar requisitos de negócio em padrões arquiteturais
- Orquestrar pessoas desenvolvedores e experts de domínio
- Entender de forma profunda conceitos e modelos arquiteturais
- Auxiliar na toma de decisão nos momentos de crise
- Reforçar boas práticas de desenvolvimento
- Fazer Code reviews
- Empresas sem o cargo de arquiteto de software, devs seniors ou tech leads realizam esse papel baseado em suas experiencias
- Empresas podem ter dpto de arquitetura, suporte para diversos times com questões arquiteturais

### Vantagens de aprender arquitetura de software

Aprender arquitetura de software oferece uma série de benefícios significativos para desenvolvedores, mesmo para aqueles que não planejam seguir uma carreira formal como arquiteto. Compreender os fundamentos da arquitetura permite que os profissionais transitem entre uma visão macro e micro dos softwares, ajudando-os a tomar decisões mais informadas sobre a estrutura e evolução dos sistemas.

O conhecimento em arquitetura amplia o "cardápio" de opções disponíveis, permitindo que desenvolvedores escolham as melhores soluções para diferentes contextos. Isso é especialmente relevante em um ambiente onde prazos e pressões são constantes, pois permite modelar o software de maneira sustentável a longo prazo, garantindo que ele continue a gerar valor para a empresa.

Além disso, a familiaridade com arquitetura de software protege contra as influências dos hypes tecnológicos, permitindo decisões mais equilibradas e alinhadas com os objetivos de negócios. Aprender arquitetura também exige um mergulho em padrões de design e boas práticas, o que enriquece o entendimento sobre como padronizar e organizar o software de maneira eficaz.

Por fim, a compreensão da arquitetura ajuda os desenvolvedores a enxergarem o impacto de seu trabalho na organização, o que pode aumentar o senso de pertencimento e motivação. Essa visão mais ampla também contribui para uma maior segurança na tomada de decisões, combatendo a insegurança e a síndrome do impostor que muitos profissionais enfrentam em algum ponto da carreira.

**Highlights**:

- Poder navegar da visão macro para a visão micro de um ou mais softwares
- Entender quais são as diversas opções que temos para desenvolver a mesma coisa e escolher a melhor solução para determinado contexto
- Pensar a longo prazo no projeto e sua sustentabilidade
- Tomar decisões de forma mais fria e calculada evitando assim ser influenciado por "hypes" de mercado
- Mergulhar em padrões de projeto e de desenvolvimento e suas boas práticas
- Ter mais clareza do impacto que o software possui na organização como um todo
Tomar deciões com mais confiança

### Arquitetura vs Design de software

Arquitetura de Software refere-se ao escopo global do software, abrangendo a visão de alto nível do sistema, como a componentização, as formas de comunicação entre componentes, e as abstrações utilizadas. A arquitetura se preocupa com atributos de qualidade, restrições de alto nível e objetivos de negócio, garantindo que o sistema atenda a esses requisitos.

Por outro lado, o Design de Software foca no escopo local, abordando questões como a organização de classes, a implementação de padrões de design, e a redução de responsabilidades dentro do código. O design lida com decisões de menor escala que, muitas vezes, não impactam diretamente na visão global do sistema.

Todas as atividades relacionadas à arquitetura de software são sempre de design, mas nem todas as atividades de design são sobre arquitetura. Isso significa que, enquanto a arquitetura sempre envolve design, o inverso não é necessariamente verdadeiro.

Por exemplo, decisões sobre a implementação de um log de sistema podem ser consideradas arquiteturais, enquanto a escolha de como organizar o código para implementar esse log pode ser considerada uma decisão de design.

**Highlights**:

- Arquitetura: Escopo global ou alto nível
- Design: Escopo local

### Sustentabilidade no dia zero

Embora o desenvolvimento de software seja caro, ele é essencial para o sucesso de empresas de tecnologia. No entanto, para que um software seja um bom investimento, ele precisa se pagar ao longo do tempo, gerando mais valor do que custa para ser mantido e evoluído.

O conceito de sustentabilidade no desenvolvimento de software envolve a capacidade do software de acompanhar a evolução do negócio. Se o software não consegue evoluir junto com a empresa, ele pode se tornar um obstáculo ao crescimento, levando a uma situação onde é necessário refazê-lo do zero, o que pode ser extremamente caro e inviabilizar a continuidade das operações da empresa.

Para evitar esse cenário, o software deve ser bem arquitetado desde o início, com foco em componentes evolutivos e escaláveis. Um software bem projetado pode continuar gerando valor para a empresa à medida que o tempo passa, pagando o investimento inicial e contribuindo para o crescimento sustentável do negócio.

Toda solução precisa ser arquitetada para garantir sua sustentabilidade desde o dia zero. Se a sustentabilidade não for considerada desde o início, o software pode se transformar em um pesadelo financeiro para a empresa, podendo até mesmo ameaçar a continuidade de suas operações. Portanto, a sustentabilidade deve ser uma prioridade desde o início do desenvolvimento do software.

**Highlights**:

- Desenvolver software é caro
- Software resolve uma "dor"
- Software precisa se pagar ao longo do tempo
- Acompanhar a evolução do negócio
- Quanto mais tempo o software ficar no ar, mais retorno gera
- A solução precisa ser arquitetada

### Pilares da arquitetura de software

Alguns conceitos essenciais que são indispensáveis para o desenvolvimento de um software de qualidade que seja capaz de evoluir ao longo do tempo:

- **Estruturação**: A base de qualquer arquitetura de software é a estruturação. Um software bem estruturado facilita sua evolução e adaptação às necessidades do negócio. Sem uma estrutura clara e sólida, o desenvolvimento de um software sustentável se torna difícil.
- **Componentização**: Um dos principais pilares é a componentização, que envolve a divisão do software em partes menores e independentes que podem evoluir separadamente. A comunicação entre esses componentes é crucial para garantir que o software como um todo funcione de maneira coesa e eficaz.
- **Relacionamento entre Sistemas**: É fundamental definir claramente como os diferentes sistemas, ou partes de um sistema, irão se comunicar. Isso inclui a escolha de protocolos, regras de segurança e a otimização do uso de recursos como a rede. Um relacionamento mal definido pode comprometer a eficácia do software.
- **Governança**: Embora possa ser confundida com burocracia, a governança em arquitetura de software é sobre estabelecer padrões, regras e documentações que guiem o desenvolvimento e a evolução do software. Isso inclui desde o uso de linguagens e protocolos até a organização de código, práticas de code review, e o gerenciamento de issues. A governança garante que o software possa evoluir independentemente das mudanças na equipe. A falta de governança pode prejudicar tanto o desenvolvimento quanto a carreira dos profissionais envolvidos, tornando-os "indispensáveis" para um projeto específico e impedindo promoções ou transferências dentro da empresa.

Uma boa arquitetura deve ser construída sobre uma base sólida, componentizada, com relacionamentos bem definidos entre sistemas e uma governança eficaz para garantir a evolução contínua do software.

**Highlights**:

- Estruturação
- Componentização
- Relacionamento entre sistemas
- Governança

### Requisitos arquiteturais

Requisitos Arquiteturais (RAs), são essenciais para o planejamento e desenvolvimento de software. É importante entender e formalizar esses requisitos para garantir que a arquitetura do software atenda às necessidades do negócio e aos padrões estabelecidos.

Mas afinal, o que são Requisitos Arquiteturais?
São requisitos não funcionais que impactam diretamente a arquitetura do software. Eles definem como o sistema deve operar e se comportar em termos de desempenho, escalabilidade, segurança, armazenamento, e conformidade legal.

**Tipos de Requisitos Arquiteturais**:

- **Performance**: Inclui requisitos como tempo de resposta (por exemplo, "a aplicação não deve ultrapassar 500 milissegundos por requisição") e throughput (por exemplo, "deve suportar 50 transações por segundo").
- **Armazenamento de Dados**: Requisitos sobre onde e como os dados são armazenados, como conformidade com regulamentos regionais (por exemplo, dados devem estar em data centers da Europa ou Brasil).
- **Escalabilidade**: Define como o software deve escalar, seja horizontalmente ou verticalmente, e como utilizar load balancers.
- **Segurança**: Inclui requisitos como criptografia de dados, certificações de segurança (por exemplo, PCI para e-commerce) e uso de MTLS para comunicação entre microsserviços.
- **Compliance Legal**: Envolve o cumprimento de legislações como a LGPD no Brasil, garantindo a proteção e auditoria de dados.
- **Auditoria**: Requisitos sobre como e por quanto tempo os dados devem ser logados e armazenados para auditorias.
- **Outros Requisitos**: Podem envolver aspectos específicos de áreas como marketing, que exigem funcionalidades para rastreamento de campanhas e personalização.

**Implementação dos Requisitos Arquiteturais**:
Tradicionalmente, a coleta de requisitos arquiteturais envolvia a criação de documentos extensos e planilhas. Hoje, embora muitas equipes usem métodos mais flexíveis e orgânicos, a clareza nos requisitos ainda é crucial. Isso envolve:

- **Entrevistas e Questionários**: Falar com especialistas de domínio, executivos e outras partes interessadas para identificar os requisitos.
- **Documentação e Planejamento**: Organizar e formalizar os requisitos para orientar a arquitetura e evitar ambiguidades durante o desenvolvimento.

**Importância dos Requisitos Arquiteturais**:
Ter uma compreensão clara dos Requisitos Arquiteturais ajuda a:

- Garantir que o software atenda às expectativas e regulamentações.
- Facilitar a comunicação entre diferentes partes da equipe.
- Prevenir problemas futuros, garantindo que a arquitetura suporte os requisitos de performance, segurança, e escalabilidade.

Embora muitos processos sejam agora mais flexíveis, a clareza e a formalização dos requisitos arquiteturais são fundamentais para o sucesso do projeto e para evitar problemas quando o software entra em produção.

**Highlights**:

- Performance
- Armazenamento de dados
- Escalabilidade
- Segurança
- Legal
- Audit
- Marketing

## Características arquiteturais

Quando desenvolvemos um sistema, ele inevitavelmente possui características arquiteturais, que podem ser tanto intencionais quanto emergentes. Entender a estrutura e os aspectos arquiteturais de um sistema é crucial para resolver problemas de forma proativa e eficiente. Se não abordarmos essas características intencionalmente, corremos o risco de lidar com problemas inesperados que poderiam ter sido prevenidos.

Intencionalidade e Resiliência:
Trabalhar de forma intencional significa preparar-se para resolver problemas específicos, em vez de depender da sorte. Por exemplo, a resiliência é uma característica essencial que permite ao software se adaptar a crises e se recuperar rapidamente. Se a resiliência não for planejada explicitamente, ela pode surgir de maneira acidental, o que não é ideal. É importante integrar a resiliência de forma planejada para evitar depender da sorte.

**Checklist Arquitetural**:
Para evitar a dependência da sorte, é útil ter uma lista de características arquiteturais a considerar durante o desenvolvimento. Essas características são frequentemente requisitos não funcionais, que garantem que o sistema suporte a carga e mantenha-se operacional de forma eficaz.

**Três Áreas de Características Arquiteturais**:

- **Áreas Operacionais**: Relacionadas ao funcionamento diário do software.
- **Características Estruturais**: Referentes à organização e estrutura interna do software.
- **Cross-Cutting**: Aspectos que afetam o sistema de forma transversal e contínua.

**Highlights**:

- Áreas Operacionais
- Características Estruturais
- Cross-Cutting
- Não contar com a sorte

### Operacionais

- **Disponibilidade**: É essencial definir claramente a disponibilidade do seu software, como o tempo em que ele estará no ar e os níveis de SLA (Service Level Agreement) e SLO (Service Level Objective). A disponibilidade deve ser planejada intencionalmente, considerando técnicas como observabilidade e orçamento para períodos de indisponibilidade.
- **Recuperação de Desastres**: Prepare-se para recuperar o sistema após falhas. Tenha processos claros para a recuperação, incluindo estratégias para lidar com falhas em regiões ou nuvens. Avalie o custo e a viabilidade de soluções como multi-região ou multi-cloud.
- **Performance**: Considere dois aspectos principais: latência e throughput. Defina os requisitos de performance do sistema, que podem variar conforme o volume de requisições. Sistemas de alta performance exigem um planejamento específico e a escolha adequada de tecnologias e arquiteturas.
- **Backup**: Garanta a eficácia dos backups, realizando testes regulares para verificar se estão funcionando corretamente. Armazene backups em locais seguros e separados para proteger contra ataques de ransomware e outros riscos.
- **Confiabilidade e Segurança**: Estabeleça medidas de segurança para proteger o sistema contra ataques, como autenticação robusta e proteção contra brute force. Confiabilidade envolve garantir que o sistema opere de forma estável e segura mesmo em situações adversas.
- **Robustez**: Avalie a capacidade do sistema de escalar e adaptar-se a mudanças na carga. Tenha em mente as limitações das infraestruturas de nuvem e planeje para situações como a falha de uma região de datacenter.
- **Escalabilidade**: Projete o sistema para escalar horizontalmente e verticalmente. A escalabilidade horizontal envolve adicionar mais instâncias, enquanto a vertical refere-se ao aumento de recursos computacionais em uma única instância. A aplicação deve ser desenvolvida para suportar a escalabilidade, seguindo boas práticas como os Twelve-Factor Apps.

Essas características operacionais são fundamentais para garantir o bom funcionamento e a resiliência do sistema.

**Highlights**:

- Disponibilidade
- Recuperação de desastres (DR)
- Performance
- Recuperação (backup)
- Confiabilidade e segurança
- Robustez
- Escalabilidade
- [12 factories](https://12factor.net/pt_br/)

### Estruturais

- **Configurabilidade**: O software deve ser fácil de configurar, permitindo alterações como conexões com bancos de dados ou APIs sem modificar o código-fonte. A capacidade de ajustar configurações através de arquivos ou variáveis de ambiente é essencial. Testar a aplicação em diferentes ambientes (produção, staging) ajuda a identificar a necessidade de mudanças no código para a configuração.
- **Extensibilidade**: A aplicação deve ser projetada para permitir a adição de novos componentes e módulos sem grandes alterações estruturais. Usar interfaces e adaptadores facilita a integração de novos fornecedores e a adição de funcionalidades, evitando a dependência excessiva de terceiros.
- **Facilidade de Instalação**: O processo de instalação deve ser simples e padronizado. O uso de containers, como Docker, pode ajudar a garantir um ambiente de execução consistente. A configuração de dependências complexas, como bancos de dados ou sistemas de busca, deve ser bem planejada para evitar dificuldades na instalação.
- **Reutilização de Componentes**: Em sistemas distribuídos, a reutilização de bibliotecas e componentes é crucial. Criar equipes dedicadas para manter bibliotecas compartilhadas pode evitar duplicação de esforços e facilitar a manutenção.
- **Internacionalização**: O software deve ser capaz de lidar com diferentes idiomas e culturas, o que inclui a configuração de moedas e políticas de preço. Considerar a internacionalização desde o início do desenvolvimento ajuda a evitar problemas futuros.
- **Facilidade de Manutenção**: Sistemas devem ser projetados para facilitar a correção de bugs e a adição de novas funcionalidades. Boas práticas incluem a adoção de testes automatizados e a utilização de design patterns para evitar acoplamentos excessivos.
- **Portabilidade**: A aplicação deve ser projetada para permitir mudanças de tecnologia ou fornecedores sem grandes reescritas. Usar ferramentas e práticas que suportam múltiplos fornecedores e tecnologias ajuda a manter a flexibilidade.
- **Observabilidade**: Implementar uma boa estratégia de observabilidade é crucial para identificar e resolver problemas. Isso inclui a criação de logs padronizados, métricas e o uso de ferramentas para centralização e análise de logs.

Essas características estruturais são fundamentais para criar aplicações robustas e adaptáveis. Use-as como um checklist para avaliar e melhorar o design de seus sistemas.

**Highlights**:

- Configurável
- Extensibilidade
- Fácil instalação
- Reuso de componentes
- Internacionalização
- Fácil manutenção
- Portabilidade
- Fácil suporte (logs, debugging)

### Cross cutting

- **Acessibilidade**: Garanta que sua aplicação seja acessível para todos, incluindo pessoas com deficiências. Utilize bibliotecas e padrões para facilitar a interação com leitores de tela e outras tecnologias assistivas.
- **Retenção e Recuperação de Dados**: Planeje a retenção dos dados de acordo com a necessidade e custo. Utilize estratégias como compactação para dados antigos e considere a política de retenção em sistemas como Kafka e Elastic Search.
- **Autenticação e Autorização**: Em arquiteturas distribuídas, use um provedor de identidade e considere a autenticação centralizada através de um API Gateway. Avalie se a autenticação deve ocorrer no nível da aplicação ou da API Gateway.
- **Conformidade Legal e Privacidade**: Assegure que sua aplicação esteja em conformidade com as leis locais e proteja a privacidade dos usuários. Separe dados sensíveis e utilize criptografia para minimizar riscos.
- **Segurança**: Implemente segurança desde a borda da aplicação até o banco de dados. Utilize padrões abertos e ferramentas de segurança reconhecidas para proteger contra vulnerabilidades como SQL Injection e XSS.
- **Usabilidade**: A usabilidade não se limita ao Front End. Garanta que sua API seja bem documentada e fácil de usar, e ofereça uma boa experiência tanto para usuários finais quanto para desenvolvedores que interagem com sua aplicação.

Essas características devem ser consideradas de forma intencional para garantir uma aplicação eficiente e segura.

**Highlights**:

- Acessibilidade
- Processo de retenção e recuperação de dados (quanto tempo os dados serão mantidos)
- Autenticação e Autorização
- Legal
- Privacidade
- Segurança
- Usabilidade

## Performance

No contexto moderno de desenvolvimento de software, alguns conceitos fundamentais desempenham um papel crucial na otimização de sistemas complexos e na melhora da experiência do usuário. Entre esses conceitos, destacam-se as métricas de performance, caching, Edge Computing e escalabilidade.

**Métricas de Performance** são essenciais para avaliar a eficiência de um sistema. Elas fornecem dados críticos que ajudam a identificar gargalos e otimizar a performance de aplicações. Esses indicadores incluem tempo de resposta, latência e uso de recursos, entre outros. A medição constante dessas métricas permite ajustes contínuos, garantindo que o sistema atenda aos requisitos de desempenho.

**Caching** é uma técnica amplamente usada para melhorar a performance, armazenando cópias de dados frequentemente acessados em locais de fácil acesso. Isso reduz a carga em servidores centrais e acelera o tempo de resposta para os usuários finais. É uma abordagem eficaz, mas deve ser cuidadosamente gerenciada para evitar inconsistências nos dados.

**Edge Computing** expande os conceitos de caching ao distribuir não apenas dados, mas também processamento para locais mais próximos dos usuários finais. Essa abordagem minimiza a latência, reduzindo o tráfego na rede e melhorando significativamente a experiência do usuário. Plataformas como Netflix e serviços de CDN, como Akamai e Cloudflare, são exemplos de como o Edge Computing pode aliviar a infraestrutura central e proporcionar uma entrega de conteúdo mais eficiente e rápida.

**Escalabilidade** é o próximo passo na evolução do sistema, permitindo que ele cresça e se adapte às mudanças nas demandas. À medida que uma aplicação ou serviço atrai mais usuários, é vital que o sistema seja capaz de se expandir, tanto verticalmente (aumentando o poder de processamento de servidores) quanto horizontalmente (adicionando mais servidores).

A combinação de boas práticas em métricas de performance, caching, Edge Computing e escalabilidade resulta em sistemas robustos, eficientes e capazes de fornecer uma excelente experiência ao usuário, mesmo sob alta demanda. Esses elementos são fundamentais na arquitetura de software moderna e devem ser cuidadosamente integrados para alcançar o sucesso a longo prazo.

### Perspectivas para arquitetar um software

Para arquitetar um software de qualidade, é essencial considerar três perspectivas principais:

- **Performance**: Avaliar e melhorar o desempenho do software é crucial. É necessário compreender as métricas que impactam a performance para garantir que o sistema funcione de forma eficiente.
- **Escalabilidade**: Um sistema escalável é capaz de crescer e atender a um número crescente de usuários e acessos, mantendo a mesma qualidade de serviço.
- **Resiliência**: Todo software está sujeito a falhas, desde bugs até problemas fora do controle dos desenvolvedores, como quedas de datacenters ou erros de configuração de rede. Portanto, é fundamental preparar o sistema para resistir a essas falhas, garantindo a continuidade do serviço.

Essas três perspectivas são fundamentais para o sucesso do software ao longo do tempo.

**Highlights**:

- Performance
- Escalabilidade
- Resiliência

### Métricas para medir a performance

Para medir e melhorar a performance de um software, é essencial entender e focar em duas métricas principais:

- **Latência (Response Time)**: Refere-se ao tempo que o sistema leva para processar e responder a uma requisição. Uma baixa latência indica que o software está respondendo rapidamente, o que é crucial para uma boa performance. Fatores como o tempo de processamento da aplicação, a qualidade da rede e a eficiência de chamadas externas podem impactar significativamente a latência.
- **Throughput**: Mede a quantidade de requisições que o sistema consegue processar simultaneamente. Aumentar o throughput significa que o software pode lidar com mais requisições ao mesmo tempo, o que melhora sua performance geral. Há uma relação estreita entre throughput e latência: quanto menor a latência, maior a capacidade do sistema de aumentar o throughput.

Melhorar a performance envolve reduzir a latência e aumentar o throughput, garantindo que o sistema seja capaz de processar requisições de maneira eficiente e rápida.

**Highlights**:

- É o desempenho que um software possui para completar um determinado workload
- As unidade de medida para avaliarmos a performance de um software:
  - Latência ou "response time"
  - Throughput
- Ter um software performático é diferente de ter um software esacalável
- Diminuindo a latência
  - Normalmente medida em **millisegundos**
  - É afetada pelo tempo de processamento da aplicação, rede e chamadas externas
- Aumentando throughput
  - Quantidade de requisições
  - Diretamente ligado a latência

### Checklist para aumento de performance

Para aumentar a performance de um software, é essencial considerar os seguintes pontos:

- **Processamento Ineficiente**: Melhorar a eficiência dos algoritmos e da aplicação como um todo. Algoritmos mal otimizados e frameworks com overhead excessivo podem prejudicar a performance.
- **Recursos Computacionais Limitados**: Avaliar se o hardware disponível é suficiente. Baixa capacidade de CPU, disco lento, pouca memória ou largura de banda de rede insuficiente podem limitar a performance.
- **Execução Bloqueante**: Evitar que a aplicação fique bloqueada em operações, permitindo o processamento de múltiplas requisições de forma simultânea, utilizando técnicas como concorrência e paralelismo.
- **Acesso Serial a Recursos**: Minimizar acessos sequenciais a APIs ou outros recursos, utilizando threads paralelas para melhorar o throughput.
- **Otimização de Algoritmos e Queries**: Melhorar as consultas ao banco de dados, usar índices adequados, evitar selects desnecessários e utilizar ferramentas de APM para identificar gargalos.
- **Concorrência e Paralelismo**: Utilizar linguagens e estratégias que permitam lidar com múltiplas operações simultâneas, como o uso de threads em Go, para aumentar a eficiência.
- **Banco de Dados**: Certificar-se de que o banco de dados está otimizado para o contexto da aplicação, com boas estratégias de modelagem, índices e monitoramento de queries.
- **Caching**: Implementar caching para evitar processamentos repetitivos, o que pode ser feito em memória, disco ou servidores separados.

Esses tópicos fornecem uma base sólida para identificar e resolver problemas de performance em sistemas, permitindo otimizações efetivas.

**Highlights**:

- Baixa performance
  - Processamento ineficiente
  - Recursos computacionais limitados
  - Trabalhar de forma bloqueante
  - Acesso serial a recursos
- Aumentar eficiência
  - Escala da capacidade computacional (CPU, Disco, Memória, Rede)
  - Lógica por trás do software (Algoritmos, queries, overhead de frameworks)
  - Concorrência e paralelismo
  - Banco de dados (tipos de bancos, schema)
  - Caching

### Escala concorrência e paralelismo

Para lidar com a capacidade computacional de sistemas, é importante entender a diferença entre escala vertical e horizontal, bem como a distinção entre concorrência e paralelismo:

- **Escala Vertical vs Escala Horizontal**:
  - **Escala Vertical**: Aumenta-se a capacidade computacional de uma única máquina, permitindo que a aplicação lide com mais requisições através de upgrades de hardware (mais CPU, memória, etc.).
  - **Escala Horizontal**: Aumenta-se o número de máquinas (ou instâncias) que lidam com as requisições, geralmente utilizando um load balancer para distribuir a carga entre elas.
- **Concorrência vs Paralelismo**:
  - **Concorrência**: É sobre lidar com várias tarefas ao mesmo tempo, como alternar entre diferentes atividades, mas sem necessariamente executá-las simultaneamente.
  - **Paralelismo**: Consiste em executar múltiplas tarefas ao mesmo tempo, efetivamente utilizando múltiplos processadores ou núcleos para processar diferentes tarefas simultaneamente.
- **Aplicação em Web Servers**: Em servidores web, a capacidade de processar requisições pode ser melhorada através da adição de threads (ou workers) para processar múltiplas requisições simultaneamente.
Linguagens como Go utilizam "green threads" que consomem menos recursos do que threads tradicionais do sistema operacional, permitindo um maior número de threads e, consequentemente, maior paralelismo e eficiência.
- **Execução Bloqueante e Não Bloqueante**:
  - **Execução Bloqueante**: As requisições são processadas de forma serial, uma de cada vez, o que pode limitar a capacidade de resposta do servidor.
  - **Execução Não Bloqueante**: Permite processar múltiplas requisições em paralelo ou de forma concorrente, aumentando o throughput do sistema.

Esses conceitos são fundamentais para otimizar a escalabilidade e a performance de aplicações, permitindo que lidem de forma eficiente com um grande número de requisições.

**Highlights**:

- Escala vertical: Aumentar recursos computacionais
- Escala horizontal: Componente de Load balancer (mais máquinas/instâncias)
- Concorrência: **lidar** com muitas coisas ao mesmo tempo
- Paralelismo: **fazer** muitas coisas ao mesmo tempo

### Caching

O cache é uma ferramenta poderosa para melhorar a performance de sistemas, reduzindo o tempo de resposta e aumentando o throughput. Ele funciona armazenando resultados previamente processados, permitindo respostas mais rápidas aos usuários sem a necessidade de reprocessar os dados. Aqui estão os principais conceitos abordados:

- **Cache na Borda (Edge Computing)**: Este tipo de cache atua antes de o usuário alcançar a infraestrutura principal, como servidores ou a nuvem. Por exemplo, com o uso de CDN (Content Delivery Network) como Cloudflare, o conteúdo estático (HTML, CSS, JavaScript) é armazenado em locais próximos ao usuário, melhorando a velocidade de carregamento.
- **Cache de Dados Estáticos**: Imagens, arquivos CSS e outros conteúdos que não mudam frequentemente podem ser cacheados para evitar o processamento repetido e reduzir a carga nos servidores.
- **Cache de Páginas Web**: Páginas inteiras ou partes delas podem ser pré-processadas e armazenadas em cache para rápida entrega ao usuário, sem necessidade de consultar o banco de dados ou processar novamente o conteúdo.
- **Cache de Funções Internas**: Algoritmos pesados que não precisam ser recalculados frequentemente podem ter seus resultados armazenados em cache, economizando processamento e tempo de resposta.
- **Cache de Objetos**: Estruturas complexas que são utilizadas repetidamente, como mapeamentos em ORMs, podem ser cacheadas para evitar recriações constantes e melhorar a eficiência.
- **Cache Exclusivo vs. Cache Compartilhado**:
  - **Cache Exclusivo**: Armazenado localmente em cada máquina, oferecendo **baixa latência**, mas com a desvantagem de **duplicação** dos dados entre diferentes servidores.
  - **Cache Compartilhado**: Armazenado em um servidor central, utilizado por todas as máquinas, evitando **duplicação** mas com **latência maior** devido ao acesso centralizado.
- **Ferramentas de Cache**: **Redis** e **Memcached** são exemplos de tecnologias utilizadas para implementar caching, com Redis sendo altamente popular por sua rapidez e eficiência em armazenar dados em memória.

Esses conceitos e técnicas são cruciais para otimizar o desempenho de sistemas, especialmente em ambientes de alta demanda, garantindo uma experiência mais ágil para o usuário.

**Highlights**:

- Cache na borda / Edge computing
- Dados estáticos
- Páginas web
- Funções internas
  - Evita reprocessamento de algoritmos pesados
  - Acesso ao banco de dados
- Objetos
- Cache Exclusivo:
  - Baixa latência
  - Duplicado entre os nós
  - Problemas relacionados a sessões
- Cache Compartilhado:
  - Maior latência
  - Não há duplicação
  - Sessões compartilhadas
  - Banco de dados externo

### Caching vs Edge Computing

Edge Computing é uma tecnologia crucial para o funcionamento eficiente da internet moderna. Ao contrário de depender de datacenters centralizados, como nos Estados Unidos, Edge Computing distribui dados e processamento para locais mais próximos dos usuários, reduzindo latência e carga na rede. Um exemplo claro é a Netflix, que, se centralizasse seus dados, sobrecarregaria tanto seus servidores quanto a internet.

Edge Computing vai além de uma CDN (Content Delivery Network); permite que dados sejam processados perto do usuário, aliviando a infraestrutura do provedor e oferecendo uma experiência melhor ao usuário final. Arquivos estáticos, como CSS e imagens, são ótimos candidatos para serem armazenados na borda (edge) da rede, economizando recursos e melhorando a performance.

CDNs como Akamai e serviços como Cloudflare Workers exemplificam o uso de Edge Computing para distribuir conteúdo eficientemente, minimizando o uso de largura de banda e custos operacionais. Plataformas como Vercel, que utiliza Edge Computing com Next.js, também destacam essa abordagem, proporcionando cache dinâmico e rápido para aplicações web.

Em resumo, Edge Computing é uma estratégia vital para otimizar o desempenho da internet, trazendo dados e processamento para mais perto dos usuários, reduzindo latência, e melhorando a experiência geral, enquanto alivia a carga nos servidores centrais.

**Highlights**:

- Cache realizado mais próximo ao usuário
- Evita a requisição chegar até o Cloud Provider / Infra
- Normalmente arquivos estáticos
- CDN - Content Delivery Network
- Cloudflare workers
- Vercel/Next.js
- Akamai

## Escalabilidade

Escalabilidade refere-se à capacidade de um sistema de lidar com o aumento ou diminuição dos workloads, ajustando os recursos computacionais de forma proporcional ao custo. Diferente da performance, que visa reduzir a latência e aumentar o throughput, escalabilidade se concentra em adaptar o throughput mediante a adição ou remoção de recursos computacionais.

Existem dois tipos principais de escalabilidade:

- **Escalabilidade Vertical**: Aumenta-se a capacidade computacional de uma única máquina, como adicionar mais memória, CPU ou velocidade de disco. Contudo, essa abordagem enfrenta limitações de hardware e riscos de falha total, caso a máquina central falhe.

- **Escalabilidade Horizontal**: Consiste em aumentar o número de máquinas. Embora não exija a melhor máquina disponível, a adição de várias máquinas distribui a carga e minimiza o impacto de falhas individuais. Isso geralmente requer a implementação de um load balancer ou proxy reverso para distribuir as requisições entre as máquinas.

No cenário atual, a escalabilidade horizontal é a abordagem mais comum devido à sua resiliência e flexibilidade, apesar das complexidades adicionais no desenvolvimento de software para suportá-la.

### Escalando aplicações

Escalar aplicações, especialmente de forma horizontal, envolve vários desafios e mudanças de paradigma em relação à arquitetura tradicional. A seguir, os pontos principais para escalar uma aplicação:

- **Máquinas Descartáveis**: Em uma arquitetura escalável, as máquinas devem ser consideradas efêmeras, ou seja, podem ser criadas ou removidas rapidamente sem afetar o sistema. Isso exige que o sistema seja projetado para operar independentemente de qualquer máquina específica.

- **Disco Efêmero**: Tudo o que é salvo no disco de uma máquina pode ser perdido a qualquer momento. Em vez de salvar dados críticos localmente, deve-se usar soluções externas, como armazenar arquivos em serviços como o S3 da AWS.

- **Separação de Servidores**: Diferencie servidores de aplicação (responsáveis por executar o código) dos servidores de assets (responsáveis por armazenar arquivos estáticos, como imagens e CSS). Isso facilita a escalabilidade, pois o servidor de aplicação pode ser destruído sem afetar os assets.

- **Cache Centralizado**: O cache deve ser armazenado em servidores externos, não nas próprias máquinas da aplicação. Isso permite que qualquer máquina acesse o cache, mantendo o desempenho e a eficiência do sistema.

- **Sessões Centralizadas**: Sessões de usuário devem ser centralizadas, normalmente em um servidor de cache, para que o login e as informações de sessão sejam consistentes, independentemente do servidor que o usuário acessar.

- **Upload e Gravação de Arquivos**: Dados importantes, como arquivos de upload ou relatórios, não devem ser armazenados localmente nas máquinas, mas em servidores externos ou buckets, para garantir que esses dados estejam disponíveis e a aplicação seja facilmente escalável.

Essas práticas garantem que o sistema possa ser escalado horizontalmente, permitindo a adição ou remoção de máquinas conforme necessário, sem perda de dados ou interrupções no serviço. A chave é descentralizar e tornar a aplicação Stateless, ou seja, sem dependência de um estado persistente em uma única máquina.

**Highlights**:

- Escalar = Descentralizar:
  - Disco efêmero: salvar somente arquivos temporários até mover para repositório externo
  - Servidor de aplicação vs Servidor de assets
  - Cache centralizado
  - Sessões centralizadas
  - Upload e gravação de arquivos

### Escalando banco de dados

Escalar bancos de dados é um desafio complexo que requer conhecimento especializado, como o de um arquiteto tecnológico ou DBA. A seguir, são abordadas as principais estratégias para escalar bancos de dados:

- **Aumento de Recursos Computacionais**: Adicionar mais CPU, memória ou discos mais rápidos pode melhorar a performance do banco de dados, mas há um limite para essa abordagem.
- **Segregação de Responsabilidades**: Separar operações de leitura e escrita pode melhorar a escalabilidade. Isso pode ser feito criando bancos de dados específicos para cada função, com réplicas de leitura para lidar com grandes volumes de consultas.
- **Escala Horizontal**: Adicionar máquinas para leitura ou utilizar diferentes formas de particionamento (sharding) permite distribuir a carga de trabalho. Diferentes tipos de bancos de dados podem ser escolhidos com base nas necessidades, como Cassandra para alta escrita ou Neo4j para relacionamentos complexos.
- **Serverless**: Utilizar serviços gerenciados na nuvem, como DynamoDB ou S3, elimina a necessidade de gerenciar servidores e facilita a escalabilidade. No entanto, é importante estar ciente das nuances relacionadas ao custo e à performance.
- **Otimização**: Antes de escalar, é essencial otimizar o banco de dados. Isso inclui o uso de índices, o monitoramento de queries com ferramentas de APM (Application Performance Monitoring), e o ajuste de queries com comandos como EXPLAIN para identificar gargalos.
- **CQRS (Command Query Responsibility Segregation)**: Este padrão separa as operações de comando (escrita) das de consulta (leitura), facilitando a otimização e escalabilidade do banco de dados.

Essas estratégias ajudam a preparar e adaptar bancos de dados para suportar uma maior carga de trabalho de forma eficiente e escalável.

**Highlights**:

- Aumentando recursos computacionais
- Distribuindo responsabilidades (escrita vs leitura)
- Shards de forma horizontal
- Serverless
- Trabalhe com índices de forma consciente
- APM (Application performance monitoring) nas queries
- Explain na queries
- CQRS

### Proxy reverso

O proxy reverso é um componente crucial na escalabilidade e performance de sistemas, sendo frequentemente utilizado para distribuir requisições e otimizar o tráfego para servidores web. Enquanto um proxy tradicional encaminha as solicitações dos usuários para sites externos, o proxy reverso funciona de maneira oposta: ele recebe as requisições dos clientes e as redireciona para um ou mais servidores específicos.

**Funcionamento**: O proxy reverso age como um intermediário entre o cliente (por exemplo, um navegador) e os servidores backend.
Com base em regras configuradas, o proxy distribui as requisições para servidores diferentes, o que pode incluir funções de balanceamento de carga (embora um proxy reverso não seja necessariamente um load balancer).
Exemplos incluem o redirecionamento de requisições para diferentes aplicações (App1, App2, App3) conforme as URLs solicitadas.

**Principais Soluções**:

- **Nginx**: Amplamente usado, é o proxy reverso mais famoso e serve como base para outras soluções, como API Gateways.
- **HAProxy**: Focado em alta disponibilidade, também é muito utilizado no mercado.
- **Traefik**: Uma solução moderna que simplifica a configuração e a operação de proxies reversos.

**Recomendação**: Aprender a configurar e trabalhar com Nginx é fundamental, já que ele é a solução mais prevalente e serve como base para muitas outras tecnologias de proxy reverso.

**Highlights**:

- Aprenda pelo menos nginx

## Resiliência

Ao trabalhar com sistemas de mensageria como Kafka, é essencial compreender os diferentes níveis de garantias de entrega:

- **Fire and Forget (Ack 0)**: Mais rápido, mas sem confirmação de entrega, podendo resultar em perda de mensagens.
- **Ack 1**: Confirmação de entrega pelo broker líder, oferecendo uma garantia moderada.
- **Ack All**: A mensagem é replicada em todos os brokers antes da confirmação, garantindo maior resiliência, mas com maior latência.

A escolha do nível de garantia deve ser feita com base na criticidade das mensagens e no impacto potencial da perda de dados.

**Situações Complexas e Decisões de Alto Nível**:

- **Resiliência**: É fundamental planejar a resiliência desde o início, mas também é necessário considerar como o sistema reagirá a falhas inesperadas, como a queda de um broker.
- **Single Point of Failure**: A dependência de um único componente pode comprometer a resiliência do sistema. Implementar estratégias como redundância e multicloud pode ajudar a mitigar esses riscos.
- **Gerenciamento de Riscos**: Aumentar a resiliência envolve custos e deve ser uma decisão estratégica tomada pelos líderes da empresa, que precisam equilibrar os custos com a necessidade de proteção contra falhas.

A resiliência e as garantias de entrega são aspectos críticos na arquitetura de software. As decisões sobre o nível de resiliência e garantias devem ser tomadas com base na importância dos dados e no impacto que falhas podem ter no negócio. As escolhas técnicas precisam estar alinhadas com a estratégia da empresa e o gerenciamento de riscos.

### Introdução a resiliência

A resiliência em software é essencial para a criação de sistemas robustos, capazes de lidar com falhas inevitáveis. Ela se refere a um conjunto de estratégias intencionais adotadas para que um sistema se adapte quando ocorre uma falha, em vez de simplesmente falhar completamente.

Resiliência implica a capacidade de um software de reconhecer problemas e acionar planos alternativos (plano B, C, etc.) para continuar funcionando, mesmo que de maneira parcial. Por exemplo, se um serviço externo, como um sistema de CEP ou uma gateway de pagamento, estiver indisponível, o sistema deve ter mecanismos para lidar com essa situação sem comprometer completamente a experiência do usuário.

Implementar resiliência exige planejamento deliberado, pois é necessário prever possíveis falhas e determinar como o software deve responder a cada uma delas. A resiliência não apenas minimiza riscos, como a perda de dados ou transações, mas também garante uma melhor experiência ao usuário final, mesmo em situações adversas. Como o autor ressalta: "Resiliência, você dobra ou quebra!"

**Highlights**:

- Adaptação: "Você se dobra ou quebra?"
- Deve ser intencional: Ter planos B, C, D, etc...
- Resiliência é um conjunto de estratégias adotadas interncionalmente para a **adaptação** de um sistema quando uma falha ocorre.
- Ter estratégias de resiliência nos possibilita minimizar os riscos de perda de dados e transações importantes para o negócio.

### Proteger e ser protegido

Para implementar resiliência em sistemas distribuídos, é essencial adotar estratégias que envolvem tanto proteger sua própria aplicação quanto proteger as aplicações com as quais ela interage. Em ambientes onde sistemas dependem uns dos outros, como em microsserviços, é crucial evitar um comportamento egoísta, onde um sistema sobrecarrega outro com requisições, especialmente quando o sistema destino já apresenta sinais de falha.

Um exemplo ilustrativo é quando o sistema "A" faz várias requisições para o sistema "B", que por sua vez depende do sistema "C". Se "C" estiver lento, isso causa um efeito dominó, onde "B" e eventualmente "A" também são impactados, comprometendo todo o ecossistema. Nesses casos, é melhor que o sistema "C" retorne uma resposta indicando que não pode processar mais requisições (por exemplo, um erro 500), em vez de tentar responder lentamente, o que pode agravar a situação.

A ideia é que os sistemas adotem uma postura mais "humanizada", reconhecendo quando estão sobrecarregados e sinalizando isso de forma clara, permitindo que outros sistemas ajustem suas ações. Assim, ao proteger sua própria aplicação, você também contribui para a estabilidade do ecossistema como um todo. Essas estratégias são mais sobre conceitos e práticas de resiliência em ambientes distribuídos do que sobre a programação em si.

**Highlights**:

- Um sistema em uma arquitetura distribuída precisa adotar mecanismos de autopreservação para garantir ao máximo sua operação com **qualidade**.
- Um sistema não pode ser egoísta ao ponto de realizar mais requisições em um sistema que está falhando.
- Um sistema lento no ar muitas vezes é pior do que um sistema fora do ar (efeito dominó).

### Health check

O health check, ou checagem de saúde, é um mecanismo essencial para monitorar a saúde de uma aplicação em tempo real, ajudando a determinar se ela está apta a receber mais requisições ou se precisa de intervenção. Ele fornece sinais vitais que indicam o estado do sistema, como a latência nas respostas ou a capacidade de acessar o banco de dados.

Um health check bem implementado vai além de simplesmente verificar se uma URL responde; ele deve incluir checagens que refletem a real saúde do sistema, como o tempo de resposta de consultas ao banco de dados. Isso evita cenários onde um sistema continua a receber requisições mesmo estando sobrecarregado, o que pode levar à sua degradação total.

Quando um sistema começa a ficar lento, o health check pode identificar esse problema e, com base nisso, parar temporariamente de direcionar tráfego para ele, permitindo que o sistema se recupere. Esse conceito é conhecido como "self healing" ou auto cura. Portanto, é crucial que o health check seja configurado estrategicamente para medir aspectos críticos do sistema e permitir ações corretivas antes que o problema se agrave.

**Highlights**:

- Sem sinais vitais, não é possível saber a saúde de um sistema.
- Um sistema que não está saudável possui uma chance de se recuperar caso o tráfego pare de ser direcionado a ele temporariamente.
- Healt check de qualidade.

### Rate limit

O rate limit é uma estratégia essencial para garantir a resiliência dos sistemas, protegendo-os ao limitar o número de requisições que podem ser processadas por segundo, baseado na capacidade projetada do sistema. Conhecer o limite que o sistema pode suportar é crucial, e, caso excedido, o sistema deve retornar um erro (como o 500) para evitar sobrecarga e falhas maiores.

No entanto, implementar um rate limit de forma genérica pode prejudicar sistemas críticos. É importante definir limites específicos para diferentes clientes ou sistemas, priorizando aqueles que são essenciais para o negócio. Por exemplo, um cliente com maior criticidade pode ter uma cota maior de requisições por segundo, enquanto sistemas menos importantes recebem uma cota menor. Isso evita que um sistema secundário monopolize os recursos, prejudicando sistemas prioritários.

Assim, o rate limit não só protege o sistema de sobrecargas, mas também assegura que os recursos sejam alocados de maneira eficiente e justa, preservando a operação dos componentes mais críticos.

**Highlights**:

- Saiba o limite do seu sistema!
- Proteja o sistema baseado no que ele foi projetado para suportar
- Preferência programada por tipo de cliente/serviço

### Circuit breaker

O circuit breaker é uma técnica de resiliência que protege sistemas de sobrecargas e falhas em cascata. Ele funciona de forma semelhante a um disjuntor elétrico: quando um sistema está sobrecarregado ou não consegue responder às requisições, o circuit breaker "abre" o circuito, retornando erros (como o 500) e interrompendo o fluxo de requisições. Isso evita que o sistema sobrecarregado se torne ainda mais instável.

Existem três estados principais no circuit breaker:

- **Circuito Fechado**: O sistema opera normalmente, aceitando todas as requisições.
- **Circuito Aberto**: O sistema está sobrecarregado, rejeitando todas as requisições com um erro imediato.
- **Meio Aberto**: O sistema permite um número limitado de requisições para testar se está se recuperando. Se as requisições forem bem-sucedidas, o circuito volta a fechar; caso contrário, permanece aberto.

O circuit breaker pode ser implementado via código ou usando ferramentas modernas como service mesh, que aplica a estratégia diretamente na rede, simplificando a configuração e gerenciamento de políticas de resiliência.

Essa técnica é crucial para evitar que um sistema sobrecarregado cause um efeito dominó, afetando outros sistemas conectados a ele.

**Highlights**:

- Protege o sistema fazendo comque as requisições feitas para ele sejam negadas. Ex: 500
- Circuito fechado: requisições chegam normalmente
- Circuito aberto: Requisições não chegam ao sistema. Erro instantâneo ao client
- Meio aberto: Permite que uma quantidade limitada de requisições para verificação se o sistema tem condições de voltar ao ar integralmente.

### API Gateway

A API Gateway é um componente crucial para gerenciar e centralizar todas as requisições de uma aplicação. Ela atua como uma "portaria", aplicando regras, políticas e validações antes de permitir que as requisições alcancem os serviços internos. Isso inclui autenticação, autorização, rate limiting, transformações de dados (como converter XML para JSON), e até mesmo o monitoramento da saúde dos serviços.

A API Gateway é essencial para garantir a resiliência da aplicação, podendo, por exemplo, bloquear requisições de robôs, validar tokens JWT, e priorizar requisições baseadas em clientes específicos. Além disso, ela pode integrar-se com outras tecnologias, como o Kong, que utiliza Nginx e oferece uma gama de plugins para implementar funcionalidades como rate limiting e health checks.

Esse componente é poderoso e flexível, mas deve ser usado com cuidado para evitar a introdução inadvertida de regras de negócios. A API Gateway facilita a aplicação de estratégias de resiliência e melhora a segurança e a eficiência das aplicações, sendo cada vez mais adotada em arquiteturas modernas.

**Highlights**:

- Garante que requisições "inapropriadas" cheguem até o sistema
- Implementa políticas de rate limit, health check, logs, auth, etc...

### Service mesh

O Service Mesh é uma solução cada vez mais popular para gerenciar e controlar o tráfego de rede entre microsserviços. Ele funciona colocando proxies (sidecars) ao lado de cada serviço, intermediando todas as comunicações. Isso permite controlar, medir e otimizar o tráfego, sem que os serviços se comuniquem diretamente.

**Principais funcionalidades**:

- **Rate Limiting**: Implementação de limites de requisições sem alterar o código da aplicação.
- **Circuit Breaker**: Controle automático das requisições, abrindo o circuito quando um serviço não consegue responder adequadamente.
- **Retry Policies**: Gerenciamento de tentativas de reenvio de requisições falhadas.
- **MTLS (Mutual TLS)**: Criptografia de comunicações, garantindo segurança contra ataques como man-in-the-middle.
- **Fault Injection**: Simulação de falhas para testar a resiliência da rede.

O Service Mesh facilita a gestão de comunicações complexas em sistemas distribuídos, automatizando tarefas que seriam complicadas e propensas a erros se feitas manualmente. Ele abstrai funções que antes eram responsabilidade dos desenvolvedores, tornando a rede mais segura, resiliente e eficiente.

**Highlights**:

- Controla o tráfego de rede
- Evita implementações de proteção pelo próprio sistema
- mTLS
- Circuit breaker, retry, timeout, fault injection, etc.

### Comunicação assíncrona

A comunicação assíncrona é uma abordagem tradicional e eficaz para melhorar a resiliência em sistemas, permitindo que as requisições sejam processadas sem a necessidade de resposta imediata. Essa metodologia é particularmente útil em cenários onde a capacidade de processamento é limitada, evitando a perda de dados e garantindo que todas as requisições sejam eventualmente atendidas.

**Principais benefícios e funcionamento**:

- **Gestão de Fila**: Quando um sistema não consegue processar todas as requisições em tempo real, as mensagens são enfileiradas, garantindo que cada uma será tratada assim que possível, semelhante ao conceito de espera em filas de banco ou supermercado.
- **Uso de Message Brokers**: A comunicação assíncrona geralmente envolve o uso de um message broker, como RabbitMQ, Kafka, ou AWS SQS. Esses brokers atuam como intermediários, armazenando as mensagens até que o sistema de destino esteja pronto para processá-las. Isso assegura que, mesmo se o sistema estiver temporariamente indisponível, as mensagens não serão perdidas.
- **Resiliência**: Ao desacoplar o envio da requisição de seu processamento imediato, é possível lidar com falhas temporárias no sistema, como reinicializações ou interrupções, sem comprometer a integridade dos dados. Assim, a comunicação assíncrona é um componente essencial para sistemas resilientes.

**Considerações adicionais**:
Embora a implementação de comunicação assíncrona possa parecer simples, é crucial entender profundamente o funcionamento do message broker escolhido. Aspectos como garantias de entrega, persistência de mensagens e políticas de retry precisam ser configurados adequadamente para evitar a perda de dados, mesmo em uma arquitetura assíncrona.

Em resumo, trabalhar de forma assíncrona permite maior flexibilidade e resiliência, ao mesmo tempo que maximiza o uso dos recursos computacionais disponíveis, assegurando a integridade dos dados em situações de alta demanda ou falhas temporárias do sistema.

**Highlights**:

- Evita perda de dados
- Não há perda de dados no envio de uma transação quando o server estiver fora
- Servidor pode processar a transação em seu tempo quando estiver online
- Entender com profundidade o message broker / sistema de stream

### Garantias de entrega com Retry

Para garantir a resiliência em sistemas distribuídos, é fundamental assegurar que as mensagens enviadas cheguem ao destino, mesmo que o sistema esteja temporariamente indisponível. Uma das principais estratégias para isso é a utilização de políticas de retry, onde a mensagem é reenviada se o sistema não responder no tempo esperado.

**Problemas com Retry Linear**:

- Reenvios em intervalos fixos (retry linear) podem sobrecarregar ainda mais um sistema já lento ou fora do ar, especialmente quando múltiplos clientes realizam retries simultâneos.

**Soluções Eficazes**:

- **Exponential Backoff**: Aumentar o intervalo entre retries de forma exponencial (por exemplo, esperar 1 segundo, depois 2, 4, 8, etc.) dá mais tempo para o sistema se recuperar antes de tentar novamente, evitando sobrecarga.
- **Exponential Backoff com Jitter**: Além do intervalo exponencial, é adicionado um pequeno ruído (jitter) no tempo de retry, como esperar 2.1 ou 2.25 segundos ao invés de 2. Esse ruído ajuda a evitar que múltiplos sistemas façam retries simultaneamente, aumentando a chance de sucesso.

**Benefícios**:

- **Redução de Sobrecarga**: O uso de jitter e exponential backoff evita que o sistema seja bombardeado com retries ao mesmo tempo, distribuindo melhor as tentativas.
- **Aumento da Resiliência**: Essas técnicas aumentam as chances de sucesso nas retentativas, contribuindo para a resiliência do sistema ao garantir que as mensagens eventualmente cheguem ao destino.

Assim, ao implementar políticas de retry, é crucial utilizar técnicas como exponential backoff com jitter para evitar sobrecarga e melhorar a eficácia das retentativas, garantindo maior resiliência do sistema.

**Highlights**:

- Linear - Sem backoff
- Exponential backoff
- Exponential backoff - Jitter

### Garantias de entrega com Kafka

Ao trabalhar com message brokers como o Kafka, é crucial entender as garantias de entrega para assegurar que mensagens importantes não sejam perdidas, especialmente em sistemas assíncronos.

**Tipos de Garantias de Entrega**:

- **Fire and Forget (Ack 0)**: A mensagem é enviada sem esperar uma confirmação do broker. Essa abordagem maximiza a velocidade, mas há o risco de perder mensagens, o que pode ser aceitável em situações onde a perda de dados não é crítica, como em atualizações frequentes de localização em um aplicativo de transporte.
- **Acknowledgment do Leader (Ack 1)**: Após enviar a mensagem, o broker líder confirma o recebimento. Isso oferece uma garantia moderada, mas se o broker líder falhar antes de replicar a mensagem para outros brokers, a mensagem pode ser perdida.
- **Acknowledgment de Todos os Brokers (Ack All)**: A mensagem é confirmada apenas quando todos os brokers no cluster replicaram a mensagem. Isso proporciona a maior garantia de entrega, mas a um custo de desempenho, já que o processo é mais lento.

**Trade-offs**:

- **Velocidade vs. Segurança**: Há um equilíbrio entre a velocidade de entrega das mensagens e a segurança da entrega. Escolher a configuração adequada (Ack 0, Ack 1, Ack All) depende da criticidade da mensagem e do nível de resiliência necessário.

**Conclusão**:
Para garantir a resiliência e segurança dos dados em sistemas que utilizam Kafka ou outros brokers similares, é essencial entender as implicações de cada tipo de acknowledgment e escolher a configuração que melhor equilibre desempenho e segurança para o seu caso de uso específico.

**Highlights**:

- Fire and Forget (Ack 0)
- Acknowledgment do Leader (Ack 1)
- Acknowledgment de Todos os Brokers (Ack All)

### Situações complexas e decisões de alto nível

A resiliência em sistemas é crucial, mas também complexa e envolve decisões estratégicas que vão além das responsabilidades dos desenvolvedores. Aqui estão os principais pontos abordados:

- **Resiliência da Resiliência**:
  - **Questões Críticas**: O que acontece se um message broker, como Kafka ou RabbitMQ, falhar? Como seu sistema se comporta? Isso pode levar a perda de mensagens ou até mesmo a uma parada do sistema.
  - **Single Point of Failure**: Dependência de um componente crítico, como o Kafka, pode ser um ponto único de falha. É essencial preparar o sistema para lidar com a falha desses componentes e garantir que a informação não seja perdida.
- **Gerenciamento de Riscos**:
  - **Custo vs. Benefício**: Aumentar a resiliência pode ser muito caro. A decisão sobre o nível de resiliência deve ser feita em níveis executivos, considerando o custo e a necessidade de proteção contra falhas.
  - **Escalabilidade e Disponibilidade**: Usar múltiplas zonas de disponibilidade (AZ) pode proteger contra falhas de uma única zona, mas a migração entre regiões ou nuvens (multicloud) para garantir alta disponibilidade pode ser mais complexa e custosa.
- **Decisões Estratégicas**:
  - **Responsabilidade dos Executivos**: Definir o nível de resiliência e os riscos associados é responsabilidade dos CTOs, CEOs e outros executivos. Eles precisam avaliar o custo e o impacto das falhas e tomar decisões com base em riscos empresariais.
  - **Desenvolvedores e Resiliência**: Desenvolvedores devem entender como implementar retries e lidar com perda de dados, mas as decisões estratégicas sobre a resiliência total do sistema são de responsabilidade dos líderes empresariais.

**Conclusão**: Resiliência é uma consideração estratégica que envolve equilibrar custo, complexidade e necessidade de proteção. As decisões sobre o nível de resiliência devem ser tomadas pelos executivos, enquanto os desenvolvedores se concentram em aspectos técnicos como retries e manejo de falhas.

**Highlights**:

- O que acontece se o message broker cair?
- Haverá perda de mensagens?
- Seu sistema ficará fora do ar?
- Como garantir resiliência?
